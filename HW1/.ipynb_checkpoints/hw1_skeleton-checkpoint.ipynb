{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnokyRPqBJ7n"
   },
   "source": [
    "# CIS 419/519 Homework 1\n",
    "\n",
    "Name: Yupeng Li\n",
    "\n",
    "Pennkey: yupengli\n",
    "\n",
    "PennID: 37169291"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXCMO-KSHept"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "random.seed(42)  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asyzto_DKfBQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8140, 1812)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGM</th>\n",
       "      <th>...</th>\n",
       "      <th>WHD080L</th>\n",
       "      <th>WHD110</th>\n",
       "      <th>WHD120</th>\n",
       "      <th>WHD130</th>\n",
       "      <th>WHD140</th>\n",
       "      <th>WHQ150</th>\n",
       "      <th>WHQ030M</th>\n",
       "      <th>WHQ500</th>\n",
       "      <th>WHQ520</th>\n",
       "      <th>DIABETIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
       "0  76195         8         2         1        18       NaN         5   \n",
       "1  76958         8         2         2        57       NaN         2   \n",
       "2  80248         8         2         2        29       NaN         2   \n",
       "3  80213         8         2         2         0       5.0         1   \n",
       "4  76753         8         2         1        61       NaN         3   \n",
       "\n",
       "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  WHD080L  WHD110  WHD120  WHD130  WHD140  \\\n",
       "0         7       1.0     217.0  ...      NaN     NaN     NaN     NaN   138.0   \n",
       "1         2       1.0       NaN  ...      NaN   135.0   115.0    67.0   150.0   \n",
       "2         2       2.0       NaN  ...      NaN     NaN   125.0     NaN   160.0   \n",
       "3         1       2.0       6.0  ...      NaN     NaN     NaN     NaN     NaN   \n",
       "4         3       2.0       NaN  ...      NaN   160.0   160.0    69.0   180.0   \n",
       "\n",
       "   WHQ150  WHQ030M  WHQ500  WHQ520  DIABETIC  \n",
       "0    18.0      NaN     NaN     NaN         0  \n",
       "1    45.0      NaN     NaN     NaN         0  \n",
       "2    28.0      NaN     NaN     NaN         0  \n",
       "3     NaN      NaN     NaN     NaN         0  \n",
       "4    30.0      NaN     NaN     NaN         0  \n",
       "\n",
       "[5 rows x 1812 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all data tables\n",
    "# baseDir = ## TODO: insert path to data file\n",
    "df = pd.read_csv('hw1-NHANES-diabetes-train.csv')\n",
    "df2 = pd.read_csv('hw1-NHANES-diabetes-test-unlabeled.csv')\n",
    "\n",
    "# Output debugging info\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvNtFvGqKfDx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of instances with missing features:\n",
      "SEQN        0.000000\n",
      "SDDSRVYR    0.000000\n",
      "RIDSTATR    0.000000\n",
      "RIAGENDR    0.000000\n",
      "RIDAGEYR    0.000000\n",
      "              ...   \n",
      "WHQ150      0.407371\n",
      "WHQ030M     0.853563\n",
      "WHQ500      0.853563\n",
      "WHQ520      0.853563\n",
      "DIABETIC    0.000000\n",
      "Length: 1812, dtype: float64\n",
      "\n",
      "Class information:\n",
      "0    7447\n",
      "1     693\n",
      "Name: DIABETIC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print information about the dataset\n",
    "print('Percentage of instances with missing features:')\n",
    "print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print()\n",
    "print('Class information:')\n",
    "print(df['DIABETIC'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH3IMkmxm3E2"
   },
   "outputs": [],
   "source": [
    "def addDummyFeatures(inputDf, feature):\n",
    "    \"\"\"\n",
    "    Create a one-hot-encoded version of a categorical feature and append it to the existing\n",
    "    dataframe.\n",
    "\n",
    "    After one-hot encoding the categorical feature, ensure that the original categorical feature is dropped\n",
    "    from the dataframe so that only the one-hot-encoded features are retained.\n",
    "\n",
    "    For more on one-hot encoding (OHE) : https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-yo u-have-to-use-it-e3c6186d008f\n",
    "\n",
    "    Arguments:\n",
    "        inputDf (Pandas.DataFrame): input dataframe\n",
    "        feature (str) : Feature for which the OHE is to be performed\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        outDf (Pandas.DataFrame): Resultant dataframe with the OHE features appended and the original feature removed\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ## TODO ##\n",
    "    if feature not in inputDf.columns:\n",
    "        return('Feature not in dataset')\n",
    "    rows,columns = inputDf.shape\n",
    "    feature_List = []\n",
    "    OHE_Matrix = np.array([[]]) #Create a matrix to store the OHE values\n",
    "    for i in range(rows):\n",
    "        if pd.isna(inputDf.loc[i,feature]):\n",
    "            OHE_Matrix = np.concatenate((OHE_Matrix,np.zeros((1,len(feature_List)))),axis=0) #If missing data, create a new row of zeros\n",
    "        elif str(inputDf.loc[i,feature]) not in feature_List:\n",
    "            feature_List.append(str(inputDf.loc[i,feature]))\n",
    "            OHE_Matrix = np.concatenate((OHE_Matrix,np.zeros((i+1,1))),axis=1)#if there is a new feature, create a new column of zeros\n",
    "        if str(inputDf.loc[i,feature]) in feature_List:\n",
    "            OHE_Matrix = np.concatenate((OHE_Matrix,np.zeros((1,len(feature_List)))),axis=0)#if this it is alreay in feature list , create a new row of zeros  and set the feature related column to 1\n",
    "            OHE_Matrix[i,feature_List.index(str(inputDf.loc[i,feature]))]=1\n",
    "    for i in range(len(feature_List)):\n",
    "        feature_List[i] = feature + '_'+feature_List[i]#New column names for OHE\n",
    "\n",
    "    OHE_Matrix = np.delete(OHE_Matrix,rows,0)#Delete the extra row created\n",
    "\n",
    "    dataOut= pd.DataFrame(OHE_Matrix,columns=feature_List) #Create a dataframe with OHE as matrix and the new feature list\n",
    "    outDf = pd.concat([inputDf,dataOut],axis=1)#Concate new features to original matrix\n",
    "    outDf = outDf.drop(feature,axis=1)#drop the original feature\n",
    "    return outDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhfk9CQoXfae"
   },
   "source": [
    "## **Preprocessing**\n",
    "\n",
    "The first key step in any data modeling task is cleaning your dataset. Explore your dataset and figure out what sort of preprocessing is required. Good preprocessing can make or break your final model. So choose wisely.\n",
    "\n",
    "Some of the preprocessing steps that you can consider are :\n",
    "\n",
    "\n",
    "*   One-hot encoding of variables\n",
    "*   Missing value imputation\n",
    "*   Removing outliers\n",
    "*   Converting binary features into 0-1 representation\n",
    "\n",
    "\n",
    "Feel free to reuse code you've already written in HW 0.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Fupod-VnNzu"
   },
   "outputs": [],
   "source": [
    "X = df.drop(['SEQN','DIABETIC','DIQ010'],axis=1)\n",
    "y = df.loc[:,'DIABETIC']\n",
    "\n",
    "\n",
    "correlation = X.corrwith(y)\n",
    "\n",
    "top30 = abs(correlation).nlargest(30).index\n",
    "\n",
    "top10 = top30[0:9]\n",
    "mid10 = top30[10:19]\n",
    "bot10 = top30[20:29]\n",
    "BestList = ['LBDSGLSI','DIQ160','RIDAGEYR','DIQ180']\n",
    "\n",
    "\n",
    "\n",
    "dropped_Features= []\n",
    "for feature in X.columns:\n",
    "    if X[feature].isnull().sum(axis=0)/X.shape[0] >= 0.5:\n",
    "        X = X.drop(feature,axis=1)\n",
    "        dropped_Features.append(feature)\n",
    "    elif X[feature].dtypes == 'O':\n",
    "        X = addDummyFeatures(X,feature)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X)\n",
    "X = pd.DataFrame(imp.transform(X),columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_HqomJOap0j"
   },
   "source": [
    "## **Modeling**\n",
    "\n",
    "In this section, you are tasked with building a Decision Tree classifier to predict whether or not a patient has diabetes. The overall goal of this exercise is to investigate the dataset and develop features that would improve your model performance.\n",
    "\n",
    "To help with this process, we have provided the structure for two helper functions. These functions will help in tuning your model as well as validating your model's performance.\n",
    "\n",
    "Complete these two functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsr6KV5wKfJB"
   },
   "outputs": [],
   "source": [
    "\n",
    "def cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "   random.seed(random_seed)\n",
    "   corrects = 0\n",
    "   testedTotal = 0\n",
    "   for i in range(num_trials):\n",
    "       index = [q for q in range(X.shape[0])]\n",
    "       random.shuffle(index)\n",
    "       shuffledDf = X.set_index([index]).sort_index()\n",
    "       sudoY = y.copy()\n",
    "       sudoY.index = index\n",
    "       shuffledy = sudoY.sort_index()\n",
    "       dfList = np.array_split(shuffledDf,num_folds)\n",
    "       yList = np.array_split(shuffledy,num_folds)    \n",
    "       for j in range(num_folds):\n",
    "           dfs = dfList.copy()\n",
    "           ys = yList.copy()\n",
    "           testDf = dfs.pop(j)\n",
    "           testy = ys.pop(j)\n",
    "           sampleDf = pd.concat(dfs,axis=0)\n",
    "           sampley = pd.concat(ys,axis=0)\n",
    "           model = DecisionTreeClassifier.fit(sampleDf,sampley)\n",
    "           predictedy = model.predict(testDf)\n",
    "           # print(f'Trial {i} Fold {j}')\n",
    "           # print((predictedy == testy).sum()/len(testy))\n",
    "           corrects += (predictedy == testy).sum()\n",
    "           testedTotal += len(testy)\n",
    "   cvScore = corrects / testedTotal\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   return cvScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNISvwuvKvjP"
   },
   "outputs": [],
   "source": [
    "\n",
    "def automatic_dt_pruning(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "  random.seed(random_seed)\n",
    "  ccp_alpha_List = np.linspace(0,1,101)\n",
    "  accuracyList = []\n",
    "  for ccp_alpha in ccp_alpha_List:\n",
    "      print(f'ccp_alpha = {ccp_alpha}')\n",
    "      DecisionTreeClassifier.set_params(ccp_alpha = ccp_alpha)\n",
    "      accuracy_Run = cross_validated_accuracy(DecisionTreeClassifier,X, y, num_trials, num_folds, random_seed)\n",
    "      print(accuracy_Run)\n",
    "      if len(accuracyList) > 0:\n",
    "          if accuracyList[-1]-accuracy_Run > 0.002:\n",
    "              return (ccp_alpha - 0.01)\n",
    "      accuracyList.append(accuracy_Run)\n",
    "      \n",
    "  ccp_alpha = ccp_alpha_List[-1]\n",
    "  \n",
    "  \"\"\"\n",
    "  Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n",
    "\n",
    "  Args:\n",
    "        DecisionTreeClassifier  : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n",
    "        X (Pandas.DataFrame)    : Input Features\n",
    "        y (Pandas.Series)       : Labels\n",
    "        num_trials              : Number of trials to run of cross validation\n",
    "        num_folds               : Number of folds for cross validation (The \"k\" in \"k-folds\") \n",
    "        random_seed             : Seed for uniform execution (Do not change this)\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n",
    "\n",
    "    Notes:\n",
    "        1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n",
    "        2. Use the cross_validated_accuracy function you implemented to find the cross-validated accuracy\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  ## TODO ##\n",
    "\n",
    "\n",
    "\n",
    "  return ccp_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LfgMo78b6SQ"
   },
   "source": [
    "## **Tuning and Testing**\n",
    "\n",
    "With the helper functions and your processed dataset, build a Decision Tree classifier to classify Diabetic patients and tune it to maximize model performance.\n",
    "\n",
    "Once you are done with your modeling process, test your model on the test dataset and output your predictions in a file titled \"cis519_hw1_predictions.csv\", with one row per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSVrMo_RcYti"
   },
   "outputs": [],
   "source": [
    "\n",
    "dtc = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "X = df[BestList]\n",
    "X2 = df2[BestList]\n",
    "for feature in X.columns:\n",
    "    if X[feature].isnull().sum(axis=0)/X.shape[0] >= 0.5:\n",
    "        X = X.drop(feature,axis=1)\n",
    "        dropped_Features.append(feature)\n",
    "    elif X[feature].dtypes == 'O':\n",
    "        X = addDummyFeatures(X,feature)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X)\n",
    "X = pd.DataFrame(imp.transform(X),columns = X.columns)\n",
    "\n",
    "for feature in X2.columns:\n",
    "    if X2[feature].isnull().sum(axis=0)/X2.shape[0] >= 0.5:\n",
    "        X = X.drop(feature,axis=1)\n",
    "        dropped_Features.append(feature)\n",
    "    elif X2[feature].dtypes == 'O':\n",
    "        X2 = addDummyFeatures(X2,feature)\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(X2)\n",
    "X2 = pd.DataFrame(imp.transform(X2),columns = X2.columns)\n",
    "\n",
    "result_ccp_alpha = automatic_dt_pruning(dtc, X, y, 10, 10, 42)\n",
    "dtc.set_params(ccp_alpha = result_ccp_alpha)\n",
    "\n",
    "dtc.fit(X,y)\n",
    "\n",
    "predictedy = np.asarray(dtc.predict(y))\n",
    "np.savetxt(\"cis519_hw1_predictions.csv\", predictedy, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
